{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "relative_path = r'C:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\src\\data_process\\transition__chord_matrix'\n",
    "\n",
    "\n",
    "def get_chord_file(relative_path) -> list:\n",
    "    \"\"\"\n",
    "    get the chord file path list\n",
    "\n",
    "    :param relative: the relative path\n",
    "    :return: chord_file_list\n",
    "    \"\"\"\n",
    "\n",
    "    chord_file_list = []\n",
    "\n",
    "    # get the file in the upper folder POP909\n",
    "    parent_path = Path(relative_path).parent\n",
    "    file_list = os.listdir(os.path.join(parent_path, 'POP909'))\n",
    "\n",
    "    # remove file that fileName is not number\n",
    "    for file in file_list:\n",
    "        if not file.isdigit():\n",
    "            file_list.remove(file)\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        chord_file = os.path.join(\n",
    "            parent_path, 'POP909', file, 'chord_midi.txt')\n",
    "        chord_file_list.append(chord_file)\n",
    "\n",
    "    return chord_file_list\n",
    "\n",
    "\n",
    "def get_beat_file(relative_path) -> list:\n",
    "    \"\"\"\n",
    "    get the beat file path list\n",
    "\n",
    "    :param relative: the relative path\n",
    "    :return: beat_file_list\n",
    "    \"\"\"\n",
    "\n",
    "    beat_file_list = []\n",
    "\n",
    "    # get the file in the upper folder POP909\n",
    "    parent_path = Path(relative_path).parent\n",
    "    file_list = os.listdir(os.path.join(parent_path, 'POP909'))\n",
    "\n",
    "    # remove file that fileName is not number\n",
    "    for file in file_list:\n",
    "        if not file.isdigit():\n",
    "            file_list.remove(file)\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        beat_file = os.path.join(parent_path, 'POP909', file, 'beat_midi.txt')\n",
    "        beat_file_list.append(beat_file)\n",
    "\n",
    "    return beat_file_list\n",
    "\n",
    "\n",
    "def get_midi_file(relative_path) -> list:\n",
    "    \"\"\"\n",
    "    get the beat file path list\n",
    "\n",
    "    :param relative: the relative path\n",
    "    :return: beat_file_list\n",
    "    \"\"\"\n",
    "\n",
    "    midi_file_list = []\n",
    "\n",
    "    # get the file in the upper folder POP909\n",
    "    parent_path = Path(relative_path).parent\n",
    "    file_list = os.listdir(os.path.join(parent_path, 'POP909'))\n",
    "\n",
    "    # remove file that fileName is not number\n",
    "    for file in file_list:\n",
    "        if not file.isdigit():\n",
    "            file_list.remove(file)\n",
    "\n",
    "    for file in file_list:\n",
    "\n",
    "        midi_file = os.path.join(parent_path, 'POP909', file, f\"{file}.mid\")\n",
    "        midi_file_list.append(midi_file)\n",
    "\n",
    "    return midi_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(chord_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    data preprocess to remove empty chord and add start_chord and end_chord\n",
    "    :param chord_df: the chord DataFrame\n",
    "    :return: chord_df\n",
    "    \"\"\"\n",
    "\n",
    "    chord_df['chord'] = chord_df['chord'].apply(lambda x: x.split('/')[0])\n",
    "    chord_df['chord'] = chord_df['chord'].apply(lambda x: x.split('(')[0])\n",
    "    return chord_df\n",
    "\n",
    "\n",
    "def merge_all_df(file_list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    merge all chord_df\n",
    "    :param file_list: the chord file list\n",
    "    :return: all_df\n",
    "    \"\"\"\n",
    "\n",
    "    all_df = pd.DataFrame()\n",
    "\n",
    "    for index, file in enumerate(file_list):\n",
    "\n",
    "        chord_df = pd.read_csv(file, sep='\\t', header=None, names=[\n",
    "                               'start_time', 'end_time', 'chord'])\n",
    "\n",
    "        chord_df = data_preprocess(chord_df)\n",
    "        chord_df['song_num'] = index + 1\n",
    "\n",
    "        all_df = pd.concat([all_df, chord_df])\n",
    "\n",
    "    all_df.to_csv(r\"csv_file/all_chord.csv\", index=True, header=True)\n",
    "    return all_df\n",
    "\n",
    "\n",
    "all_file = get_chord_file(relative_path)\n",
    "all_chord = merge_all_df(all_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all beat file\n",
    "\n",
    "def read_all_beat_file(all_file):\n",
    "\n",
    "    all_beat = []\n",
    "    for index, file in enumerate(all_file):\n",
    "\n",
    "        downBeatTimes = []\n",
    "        bars = []\n",
    "        # read the txt to pd\n",
    "        df = pd.read_csv(file, sep=\" \", header=None)\n",
    "\n",
    "        # remove the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "\n",
    "        original = df.copy()\n",
    "        # if last column is 1, append first colum's value to downbeat\n",
    "        for i in range(0, len(df)):\n",
    "            if df.iloc[i, -1] == 1:\n",
    "                downBeatTimes.append(df.iloc[i, 0])\n",
    "\n",
    "        # calculate the bars\n",
    "        for i in range(0, len(downBeatTimes)-1):\n",
    "            bars.append([downBeatTimes[i], downBeatTimes[i+1]])\n",
    "        bars.append([bars[-1][1], df.iloc[-1, 0]])\n",
    "\n",
    "        all_beat.append(bars)\n",
    "\n",
    "    return all_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import pandas as pd\n",
    "\n",
    "pitch_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "\n",
    "def process_row(row, song_num):\n",
    "\n",
    "    start = row['Timestamp'][0]\n",
    "    end = row['Timestamp'][1]\n",
    "\n",
    "    # make copy of df_chord\n",
    "    df_chord_copy = all_chord[all_chord['song_num'] == song_num].copy()\n",
    "    # calculate the gap between start and end\n",
    "    df_chord_copy[\"gap\"] = df_chord_copy.apply(lambda x: abs(\n",
    "        x['start_time'] - start) + abs(x['end_time'] - end), axis=1)\n",
    "\n",
    "    # find the min gap\n",
    "    min_gap = df_chord_copy['gap'].min()\n",
    "\n",
    "    # find the chord\n",
    "    chord = df_chord_copy[df_chord_copy['gap'] == min_gap]['chord'].values[0]\n",
    "    return chord\n",
    "\n",
    "\n",
    "def midi_note_to_pitch(midi_note) -> str:\n",
    "    \"\"\"\n",
    "    the function to convert midi note to pitch\n",
    "    param midi_note: int\n",
    "    return: str\n",
    "    \"\"\"\n",
    "\n",
    "    # Equal temperament\n",
    "\n",
    "    octave = (midi_note - 12) // 12 + 1\n",
    "    pitch_class = midi_note % 12\n",
    "    pitch_name = pitch_names[pitch_class]\n",
    "    return f'{pitch_name}'\n",
    "\n",
    "\n",
    "def split_midi_to_measure(midi_file: str, time_section: list) -> list:\n",
    "    \"\"\"\n",
    "    the function to split midi song into list of measure\n",
    "\n",
    "    Args:\n",
    "        midi_file (str): the midi file name\n",
    "        time_section (list): the time section of the midi\n",
    "    Returns:\n",
    "        the list of note split by measure    \n",
    "    \"\"\"\n",
    "\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "\n",
    "    measure_list = []\n",
    "\n",
    "    # accroding to time section to find the note events\n",
    "    for i in range(0, len(time_section)):\n",
    "        measure = []\n",
    "\n",
    "        for note in midi_data.instruments[0].notes:\n",
    "            if note.start >= time_section[i][0] and note.start < time_section[i][1]:\n",
    "                measure.append(midi_note_to_pitch(note.pitch))\n",
    "\n",
    "        measure_list.append(measure)\n",
    "\n",
    "    return measure_list\n",
    "\n",
    "\n",
    "def convert_bar_notes_to_12d_vector(bars_notes: list) -> list:\n",
    "    \"\"\"\n",
    "    the function to convert bar notes to 12d vector\n",
    "    C, C#, D, D#, E, F, F#, G, G#, A, A#, B\n",
    "    param bars_notes: list\n",
    "    return: list\n",
    "    \"\"\"\n",
    "    bars_notes_vector = []\n",
    "    # 12d vector to represent the note show times\n",
    "    # if the note show in the bar, the value will add 1\n",
    "    # if the note not show in the bar, the value will be 0\n",
    "\n",
    "    for i in range(0, len(bars_notes)):\n",
    "        note_vector = [0] * 12\n",
    "        for note in bars_notes[i]:\n",
    "\n",
    "            if note not in pitch_names:\n",
    "                print(note)\n",
    "            note_vector[pitch_names.index(note)] += 1\n",
    "\n",
    "        bars_notes_vector.append(note_vector)\n",
    "\n",
    "    return bars_notes_vector\n",
    "\n",
    "\n",
    "def data_preprocess_pipeline(file, bar, index):\n",
    "\n",
    "    song_num = index + 1\n",
    "    bars_notes = split_midi_to_measure(file, bar)\n",
    "    bars_notes_vector = convert_bar_notes_to_12d_vector(bars_notes)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Melody': bars_notes_vector,\n",
    "        'Timestamp': bar,\n",
    "        'song_num': song_num,\n",
    "    })\n",
    "\n",
    "    df['chord'] = df.apply(process_row, axis=1, args=(song_num,))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\src\\lstm\\data_preprocess.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_beat \u001b[39m=\u001b[39m read_all_beat_file(get_beat_file(relative_path))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m all_midi \u001b[39m=\u001b[39m get_midi_file(relative_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_all_df_dataset\u001b[39m(all_midi, all_beat):\n",
      "\u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\src\\lstm\\data_preprocess.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m bars \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# read the txt to pd\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# remove the last column\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hsieh/Documents/nccucs/specialTopic/special_topic/src/lstm/data_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Hsieh\\Documents\\nccucs\\specialTopic\\special_topic\\venv\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[0;32m    304\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    byte sequences.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    310\u001b[0m         IncrementalDecoder\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, errors)\n\u001b[0;32m    311\u001b[0m         \u001b[39m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "all_beat = read_all_beat_file(get_beat_file(relative_path))\n",
    "all_midi = get_midi_file(relative_path)\n",
    "\n",
    "\n",
    "def merge_all_df_dataset(all_midi, all_beat):\n",
    "    merge_df = pd.DataFrame()\n",
    "    for i in range(0, len(all_midi)):\n",
    "\n",
    "        print(f\"processing {i+1} song\")\n",
    "\n",
    "        # Print %\n",
    "        print(f\"{round((i+1)/len(all_midi)*100,2)}%\")\n",
    "\n",
    "        df = data_preprocess_pipeline(all_midi[i], all_beat[i], i)\n",
    "        merge_df = pd.concat([merge_df, df])\n",
    "\n",
    "    return merge_df\n",
    "\n",
    "\n",
    "merge_df = merge_all_df_dataset(all_midi, all_beat)\n",
    "merge_df.to_csv(r\"csv_file/merge_df_dataset.csv\", index=True, header=True)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv as pd\n",
    "\n",
    "# remove colum chord where is n and melody where is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"csv_file/merge_df_dataset.csv\", index_col=0)\n",
    "\n",
    "df = df[df['chord'] != 'N']\n",
    "df = df[df[\"Melody\"] != '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]']\n",
    "\n",
    "\n",
    "\n",
    "def adree_not_in_top_24 (chord):\n",
    "   \n",
    "   # replace number with \"\" in str\n",
    "\n",
    "\n",
    "    chord = chord.replace(\"1\", \"\")\n",
    "    chord = chord.replace(\"2\", \"\")\n",
    "    chord = chord.replace(\"3\", \"\")\n",
    "    chord = chord.replace(\"4\", \"\")\n",
    "    chord = chord.replace(\"5\", \"\")\n",
    "    chord = chord.replace(\"6\", \"\")\n",
    "    chord = chord.replace(\"7\", \"\")\n",
    "    chord = chord.replace(\"8\", \"\")\n",
    "    chord = chord.replace(\"9\", \"\")\n",
    "    chord = chord.replace(\"0\", \"\")\n",
    "        #replace \"sus\" with \"maj\"\n",
    "    \n",
    "    chord = chord.replace(\"sus\", \"maj\")\n",
    "       #replace \"dim\" with \"min\"\n",
    "    \n",
    "    chord = chord.replace(\"dim\", \"min\")   \n",
    "    #replace \"minmaj\", \"hmin\" with \"min\"\n",
    "    \n",
    "    chord = chord.replace(\"minmaj\", \"min\") \n",
    "    chord = chord.replace(\"hmin\", \"min\")  \n",
    "    #replace \"aug\"with \"maj\"\n",
    "    \n",
    "    chord = chord.replace(\"aug\", \"maj\") \n",
    "        \n",
    "    #if last word is \":\"\n",
    "    if chord[-1] == \":\":\n",
    "        #append \"maj\"\n",
    "        chord = chord + \"maj\"\n",
    "      \n",
    "   \n",
    "   \n",
    "    return chord\n",
    "\n",
    "#convert chord to 24 chord using adree_not_in_top_24 (chord)\n",
    "\n",
    "df['chord'] = df['chord'].apply(adree_not_in_top_24)\n",
    "\n",
    "#save to csv file\n",
    "df.to_csv(r\"csv_file/merge_df_dataset.csv\", index=True, header=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
