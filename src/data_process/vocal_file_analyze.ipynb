{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated tempo: 89.10 beats per minute\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.13931972789115646, 2.9257142857142857],\n",
       " [2.9257142857142857, 5.712108843537415],\n",
       " [5.712108843537415, 8.475283446712018],\n",
       " [8.475283446712018, 11.00625850340136],\n",
       " [11.00625850340136, 13.49079365079365],\n",
       " [13.49079365079365, 16.32362811791383],\n",
       " [16.32362811791383, 19.086802721088436],\n",
       " [19.086802721088436, 22.076462585034015]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beat tracking example\n",
    "import librosa\n",
    "\n",
    "# 1. Get the file path to an included audio example\n",
    "filename = \"C:\\\\Users\\\\Hsieh\\\\Documents\\\\nccucs\\\\specialTopic\\\\special_topic\\\\src\\\\auto_accompany\\\\audio\\\\vocal\\\\input.9.mp3\"\n",
    "\n",
    "\n",
    "# 2. Load the audio as a waveform `y`\n",
    "#    Store the sampling rate as `sr`\n",
    "y, sr = librosa.load(filename)\n",
    "\n",
    "\n",
    "# 3. Run the default beat tracker\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "print('Estimated tempo: {:.2f} beats per minute'.format(tempo))\n",
    "\n",
    "# 4. Convert the frame indices of beat events into timestamps\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "beat_times \n",
    "\n",
    "#get A  element index multiple of 4 from 0\n",
    "down_beat = beat_times[0::4]\n",
    "\n",
    "\n",
    "#convert to time section group by 2 and the last elemnt cotinue to end\n",
    "time_section = []\n",
    "for i in range(0,len(down_beat)-1):\n",
    "    time_section.append([down_beat[i],down_beat[i+1]])\n",
    "time_section.append([down_beat[-1],librosa.get_duration(y=y, sr=sr)])\n",
    "\n",
    "time_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.786394557823129,\n",
       " 2.786394557823129,\n",
       " 2.763174603174603,\n",
       " 2.5309750566893428,\n",
       " 2.4845351473922896,\n",
       " 2.832834467120181,\n",
       " 2.7631746031746047,\n",
       " 2.9896598639455796]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the gap in  time section \n",
    "gap = []\n",
    "for i in range(0,len(time_section)):\n",
    "    gap.append(time_section[i][1]-time_section[i][0])\n",
    "gap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A#', 'A#', 'G', 'A', 'G', 'G', 'E', 'F', 'F'],\n",
       " ['F', 'F', 'G', 'F', 'F', 'F', 'F', 'F'],\n",
       " ['A', 'A#', 'A#', 'G', 'A', 'G', 'G', 'G', 'G'],\n",
       " ['F', 'F', 'G', 'F', 'E', 'F', 'F'],\n",
       " ['D', 'C', 'G', 'A', 'F'],\n",
       " ['F', 'F', 'F', 'F', 'G', 'F', 'F', 'F', 'F'],\n",
       " ['C#', 'D', 'C#', 'C#', 'B', 'G#', 'G#', 'G#', 'G#'],\n",
       " ['F#', 'F', 'F', 'F', 'F#', 'E', 'F', 'F']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse midi and find the note events in beat_times\n",
    "import pretty_midi\n",
    "def midi_note_to_pitch(midi_note) -> str:\n",
    "    \"\"\"\n",
    "    the function to convert midi note to pitch\n",
    "    param midi_note: int\n",
    "    return: str\n",
    "    \"\"\"\n",
    "\n",
    "    # Equal temperament\n",
    "    pitch_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    octave = (midi_note - 12) // 12 + 1\n",
    "    pitch_class = midi_note % 12\n",
    "    pitch_name = pitch_names[pitch_class]\n",
    "    return f'{pitch_name}'\n",
    "\n",
    "\n",
    "midi_data = pretty_midi.PrettyMIDI('C:\\\\Users\\\\Hsieh\\\\Documents\\\\nccucs\\\\specialTopic\\\\special_topic\\\\src\\\\auto_accompany\\\\midi\\\\midi_output_voice.mid')\n",
    "measure_list = []\n",
    "\n",
    "  \n",
    "\n",
    "#accroding to time section to find the note events\n",
    "for i in range(0,len(time_section)):\n",
    "    measure = []\n",
    "    for note in midi_data.instruments[0].notes:\n",
    "        if note.start >= time_section[i][0] and note.start < time_section[i][1]:\n",
    "            measure.append(midi_note_to_pitch(note.pitch) )\n",
    "    measure_list.append(measure)\n",
    "\n",
    "measure_list\n",
    "            \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complte\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "midi_file = \"C:\\\\Users\\\\Hsieh\\\\Documents\\\\nccucs\\\\specialTopic\\\\special_topic\\\\src\\\\data_process\\\\chords_output.mid\"\n",
    "wav_file = \"chords_output.wav\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_midi_to_wav(midi_path, wav_path):\n",
    "    fluidsynth_cmd = ['fluidsynth', '-F', wav_path]\n",
    "   \n",
    "    fluidsynth_cmd += [midi_path]\n",
    "\n",
    "    subprocess.run(fluidsynth_cmd)\n",
    "\n",
    "\n",
    "convert_midi_to_wav(midi_file, wav_file)\n",
    "\n",
    "print(\"complte\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
